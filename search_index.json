[
["index.html", "The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Preface About this book Who is this book for? Outline Topics this book does not cover About the authors Acknowledgements", " The Hitchhiker’s Guide to the tlverse or a Targeted Learning Practitioner’s Handbook Jeremy Coyle, Nima Hejazi, Ivana Malenica, Rachael Phillips, Alan Hubbard, Mark van der Laan March 27, 2019 Preface About this book The Hitchhiker’s Guide to the tlverse, or a Targeted Learning Practitioner’s Handbook is an open-source and fully-reproducible electronic handbook for applying the targeted learning methodology in practice using the tlverse software ecosystem. This work is currently in an early draft phase and is available to facilitate input from the community. To view or contribute to the available content, consider visiting the GitHub repository for this site. Who is this book for? TODO Outline TODO Topics this book does not cover TODO For technical detail, consider consulting van der Laan and Rose (2011) and van der Laan and Rose (2018). About the authors 0.0.1 Jeremy Coyle Jeremy R. Coyle is a consulting data scientist and statistical programmer, currently leading the software development effort that has produced the tlverse ecosystem of R packages and related software tools. Jeremy earned his Ph.D. in Biostatistics from UC Berkeley in 2016, primarily under the supervision of Alan Hubbard. Nima Hejazi Nima S. Hejazi is a Ph.D. candidate in biostatistics with a designated emphasis in computational and genomic biology, working jointly with Mark van der Laan and Alan Hubbard. Nima is affiliated with UC Berkeley’s Center for Computational Biology and NIH Biomedical Big Data training program. His research interests span causal inference, nonparametric inference and machine learning, targeted loss-based estimation, survival analysis, statistical computing, reproducible research, and high-dimensional biology. He is also passionate about software development for applied statistics, including software design, automated testing, and reproducible coding practices. For more information, see https://nimahejazi.org. Ivana Malenica Ivana Malenica is a Ph.D. student in biostatistics advised by Mark van der Laan. Ivana is currently a fellow at the Berkeley Institute for Data Science, after serving as a NIH Biomedical Big Data and Freeport-McMoRan Genomic Engine fellow. She earned her Master’s in Biostatistics and Bachelor’s in Mathematics, and spent some time at the Translational Genomics Research Institute. Very broadly, her research interests span non/semi-parametric theory, probability theory, machine learning, causal inference and high-dimensional statistics. Most of her current work involves complex dependent settings (dependence through time and network) and adaptive sequential designs. Rachael Phillips Rachael V. Phillips is a Ph.D. student in biostatistics, advised by Alan Hubbard and Mark van der Laan. She has an M.A. in Biostatistics, B.S. in Biology with a Chemistry minor and a B.A. in Mathematics with a Spanish minor. Rachael is motivated to solve real-world, high-dimensional problems in human health. Her research interests span causal inference, machine learning, nonparametric statistical estimation, and finite sample inference. She is also passionate about online mediated education. Rachael is affiliated with UC Berkeley’s Center for Computational Biology, NIH Biomedical Big Data Training Program, and Superfund Research Program. Alan Hubbard Alan E. Hubbard is Professor of Biostatistics, former head of the Division of Biostatistics at UC Berkeley, and head of data analytics core at UC Berkeley’s SuperFund research program. His current research interests include causal inference, variable importance analysis, statistical machine learning, estimation of and inference for data-adaptive statistical target parameters, and targeted minimum loss-based estimation. Research in his group is generally motivated by applications to problems in computational biology, epidemiology, and precision medicine. Mark van der Laan Mark J. van der Laan, PhD, is Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in computational biology, survival analysis, censored data, adaptive designs, targeted maximum likelihood estimation, causal inference, data-adaptive loss-based learning, and multiple testing. His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for the estimation of infinite-dimensional parameters, such as nonparametric density estimation and prediction with both censored and uncensored data. Building on this work, his research group developed targeted maximum likelihood estimation for a target parameter of the data-generating distribution in arbitrary semiparametric and nonparametric models, as a generic optimal methodology for statistical and causal inference. Most recently, Mark’s group has focused in part on the development of a centralized, principled set of software tools for targeted learning, the tlverse. For more information, see https://vanderlaan-lab.org. Acknowledgements … References "],
["intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 1. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 3. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2019) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["literature.html", "Chapter 2 Literature", " Chapter 2 Literature Here is a review of existing methods. "],
["methods.html", "Chapter 3 Methods", " Chapter 3 Methods We describe our methods in this chapter. "],
["optimal-individualized-treatment-regimes.html", "Chapter 4 Optimal Individualized Treatment Regimes 4.1 Learning Objectives 4.2 Introduction to Optimal Individualized Interventions 4.3 Data Structure and Notation 4.4 Defining the Causal Effect of an Optimal Individualized Intervention 4.5 Interpreting the Causal Effect of an Optimal Individualized Intervention 4.6 Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment 4.7 Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment 4.8 Extensions: Variable Importance Analysis with Optimal Individualized Interventions 4.9 Exercises", " Chapter 4 Optimal Individualized Treatment Regimes Ivana Malenica, Jeremy Coyle, Mark van der Laan Updated: 2019-03-27 4.1 Learning Objectives … … … … … 4.2 Introduction to Optimal Individualized Interventions The aim of precision medicine is to allow for patient specific interventions. In the case of categorical treatment, one opts to administer the intervention to individuals who will benefit from it, instead of assigning treatment on a population level. For example, Abacavir and Tenofovir are commonly prescribed as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV) patients. However, not all individuals benefit from the two medications equally. In particular, patients with renal dysfunction might further deteriorate if prescribed Tenofovir, due to the high nephrotoxicity caused by the medication. While Tenofovir is still highly effective treatment option for HIV patients, in order to maximize the patient’s well-being, it would be benefitial to prescribe Tenofovir only to individuals with healthy kindey function. This motivates a diffent type of interention, as opposed to the static exposures we might be used to. In particular, in this chapter we learn about dynamic or individualized interventions that tailor the treatment decision based on the collected covariates. In the statistics community such a treatment strategy is termed The problem of estimating the optimal individualized treatment has received much attention in the statistics literature over the years, especially with the advancement of precision medicine; see Murphy (2003), (“Temporary,” n.d.), (“Temporary,” n.d.) and (“Temporary,” n.d.) to name a few. However, much of the early work depends on parametric assumptions. As such, even in a randomized trial, the statistical inference for the optimal individualized treatment relies on assumptions that are generally believed to be false, and can lead to biased results. In this chapter, we consider estimation of the mean outcome under the optimal individualized treatment where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates. The estimation problem is addressed in a statistical model for the data distribution that is nonparametric, and at most places restrictions on the probability of a patient receiving treatment given covariates (as in a randomized trial). As such, we don’t need to make any assumptions about the relationship of the outcome with the treatment and covariates, or the relationship between the treatment and covariates. For a technical presentation of the algorithm, the interested reader is invited to further consult van der Laan and Luedtke (2015) and Luedtke and van der Laan (2016). For additional background on Targeted Learning, please consider consulting van der Laan and Rose (2011) and van der Laan and Rose (2018). 4.3 Data Structure and Notation Suppose we observe \\(n\\) independent and identically distributed observations of the form \\(O=(W,A,Y) \\sim P_0\\). We denote \\(A\\) as categorical treatment, and \\(Y\\) as the final outcome. Note that we treat \\(W\\) as vector-valued, representing all of our collected baseline covariates. Therefore, for a single random individual \\(i\\), we have that their observed data is \\(O_i\\): with corresponding baseline covariates \\(W_i\\), treatment \\(A_i\\), and final outcome \\(Y_i\\). We say that \\(O \\sim P_0\\), or that all data was drawn from some probability distribution \\(P_0\\). We emphasize that we make no assumptions about the distribution of \\(P_0\\), so that \\(P_0 \\in \\mathcal{M}\\), where \\(\\mathcal{M}\\) is the fully nonparametric model. We can break the data generating distribution \\(P_0\\) into the following parts by time ordering: \\[P_0(O) = P_0(Y|A,W)P_0(A|W)P_0(W) = Q_{Y,0}(Y|A,W)g_0(A|W)Q_{W,0}(W)\\] where \\(P_0(Y|A,W)=Q_{Y,0}(Y|A,W)\\), \\(P_0(A|W)=g_0(A|W)\\) and \\(P_0(W)=Q_{W,0}(W)\\). For notational simplicity, we also define \\(\\bar{Q}_{Y,0}(A,W) \\equiv E_0[Y|A,W]\\). 4.4 Defining the Causal Effect of an Optimal Individualized Intervention Many methods for learning an optimal rule from data have been developed. Here, we focus on the methods developed in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015); however tmle3mopttx also supports the widely used Q-learning approach, based on generating an estimate of \\(\\bar{Q}_{Y,0}(A,W)\\) Sutton, Barto, and others (1998). We cover how to use the Q-learning approach in the later implementation of the vignette. However, we focus on the methodology outlined in Luedtke and van der Laan (2016) and van der Laan and Luedtke (2015), where we learn the optimal ITR using Super Learner van der Laan, Polley, and Hubbard (2007), and estimate its value using the cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) Zheng and van der Laan (2010). Luedtke and van der Laan present three different appraches for learning the optimal rule, but tmle3mopttx relies on using the Super Learner to estimate the blip function (or “pseudo-blip” for categorical treatment). In great generality, we first need to estimate an individual treatment regime which corresponds to dynamic treatment rule (\\(d(V)\\)) that takes a subset of covariates \\(V \\in W\\) and assigns treatment. As specified in the introduction, we are also interested in the value of such a dynamic rule: \\[E_0[Y_{d(V)}] = E_{0,W}[\\bar{Q}_{Y,0}(A=d(V),W)]\\] which, under causal assumptions, can be interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. The optimal rule is the rule with the maximal value: \\[d_0 \\equiv \\text{argmax}_{d \\in \\mathcal{D}} E_0[Y_{d(V)}] \\] where \\(\\mathcal{D}\\) represents the set of possible rules, \\(d\\). We note that minimization is completely ok as well, depending on the problem in hand. 4.4.1 Binary treatment In the case of a binary treatment, a key quantity for optimal ITR is the blip function. In particular, one can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, we define a blip function as \\[E_0[Y_1-Y_0|V] \\equiv E_0[\\bar{Q}_{Y,0}(1,W) - \\bar{Q}_{Y,0}(0,W) | V] \\] The note that the rule can now be derived as \\(d_0(V) = I(\\bar{Q}_0(V) &gt; 0)\\). In particular, we will: Estimate \\(\\bar{Q}_{Y,0}(A,W)\\) and \\(g_0(A|W)\\) using sl3. Apply the doubly robust A-IPW transform to our outcome, where we define: \\[D_{\\bar{Q},g,a}(O) \\equiv \\frac{I(A=a)}{g(A|W)} (Y-\\bar{Q}_Y(A,W)) + \\bar{Q}_Y(A=a,W),\\] Using this transform, we can define the following contrast: \\(D_{\\bar{Q},g}(O) = D_{\\bar{Q},g,a=1}(O) - D_{\\bar{Q},g,a=0}(O)\\) We estimate the blip function ({Q}_{0,a}(V)) by regressing \\(D_{\\bar{Q},g}(O)\\) on \\(V\\) using sl3. Our estimated rule is \\(d(V) = \\text{argmax}_{a \\in \\mathcal{A}} \\bar{Q}_{0,a}(V)\\). Obtain inference for the mean outcome under the optimal rule using CV-TMLE. 4.4.2 Categorical treatment In line with the approach considered for binary treatment, we extend the blip function apprach to allow for categorical treatment by estimating “pseudo-blips”. We define pseudo-blips as vector valued entities where the output for a given \\(V\\) is a vector of length equal to the number of treatment categories. As such, we define it as: \\[\\bar{Q}_0^{pblip}(V) = \\{\\bar{Q}_{0,a}^{pblip}(V): a \\in \\mathcal{A} \\}\\] We implement three different pseudo-blips in tmle3mopttx. “Blip1” corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: \\[\\bar{Q}_{0,a}^{pblip-ref}(V) \\equiv E_0(Y_a-Y-0|V)\\] where \\(Y_0\\) is the specified reference category. Note that, for the case of binary treatment, this strategy reduces to the apparoach described in the previous section. “Blip2” approach corresponds to defining the blip relative to the average of all categories. As such, we can define \\(\\bar{Q}_{0,a}^{pblip-avg}(V)\\) as: \\[\\bar{Q}_{0,a}^{pblip-avg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a^{&#39;} \\in \\mathcal{A}} Y_{a^{&#39;}}|V)\\] “Blip3” reflects an extension of “Blip2”, where the average is now a weighted average. \\[\\bar{Q}_{0,a}^{pblip-wavg}(V) \\equiv E_0(Y_a- \\frac{1}{n_A} \\sum_{a^{&#39;} \\in \\mathcal{A}} P(A=a^{&#39;}|V) Y_{a^{&#39;}}|V)\\] Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on \\(V\\). 4.5 Interpreting the Causal Effect of an Optimal Individualized Intervention TODO 4.6 Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment TODO 4.7 Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment To start, let’s load the packages we’ll use and set a seed for simulation: library(data.table) library(sl3) library(tmle3) library(tmle3mopttx) library(devtools) set.seed(111) 4.7.1 Simulated Data First, we load the simulated data. Here, our data generating distribution is of the following form: \\[W \\sim \\mathcal{N}(\\bf{0},I_{4 \\times 4})\\] \\[P(A=a|W) = \\frac{1}{1+\\exp^{(-0.8*W_a)}}\\] \\[P(Y=1|A,W) = 0.5\\text{logit}^{-1}[3I(A=1)(W_1-0.5) - 3I(A=2)(2W_2+0.5) + 3I(A=3)(3W_3-0.5)] +\\text{logit}^{-1}(W_2W_3)\\] data(&quot;data_cat&quot;) The above composes our observed data structure \\(O = (W, A, Y)\\). Note that the mean under the true optimal rule is \\(\\psi=0.625\\). To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: # organize data and nodes for tmle3 data &lt;- data_cat node_list &lt;- list( W = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), A = &quot;A&quot;, Y = &quot;Y&quot; ) We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. 4.7.2 Constructing Optimal Stacked Regressions with sl3 To easily incorporate ensemble machine learning into the estimation procedure, we rely on the facilities provided in the sl3 R package. For a complete guide on using the sl3 R package, consider consulting https://sl3.tlverse.org, or https://tlverse.org for the tlverse ecosystem, of which sl3 is a major part. Using the framework provided by the sl3 package, the nuisance parameters of the TML estimator may be fit with ensemble learning, using the cross-validation framework of the Super Learner algorithm of van der Laan, Polley, and Hubbard (2007). #Initialize some of the learners. #Here we use xgboost with various parameters, glm, HAL and the simle mean. xgboost_50&lt;-Lrnr_xgboost$new(nrounds = 50) xgboost_100&lt;-Lrnr_xgboost$new(nrounds = 100) xgboost_500&lt;-Lrnr_xgboost$new(nrounds = 500) lrn1 &lt;- Lrnr_mean$new() lrn2&lt;-Lrnr_glm_fast$new() lrn3&lt;-Lrnr_hal9001$new() #Define the Q learner, which is just a regular learner: Q_learner &lt;- Lrnr_sl$new( learners = list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2), metalearner = Lrnr_nnls$new() ) #Define the g learner, which is a multinomial learner: glib &lt;- list( rf &lt;- make_learner(Lrnr_randomForest), xgb &lt;- make_learner(Lrnr_xgboost), glmnet &lt;- make_learner(Lrnr_glmnet), multinom_gf &lt;- make_learner(Lrnr_independent_binomial, make_learner(Lrnr_glm_fast)), mean &lt;- make_learner(Lrnr_mean) ) mn_metalearner &lt;- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, learner_function = metalearner_linear_multinomial) g_learner &lt;- make_learner(Lrnr_sl, glib, mn_metalearner) #Define the Blip learner, which is a multivariate learner: learners &lt;- list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2) b_learner &lt;- create_mv_learners(learners = learners) As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate \\(g_0(A|W)\\) for a categorical \\(A\\)- therefore we use the multinomial Super Learner option available within the sl3 package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate \\(g_0(A|W)\\) in sl3, we run the following: #See which learners support multi-class classification: sl3_list_learners(c(&quot;categorical&quot;)) [1] &quot;Lrnr_bartMachine&quot; &quot;Lrnr_dbarts&quot; [3] &quot;Lrnr_glmnet&quot; &quot;Lrnr_grf&quot; [5] &quot;Lrnr_h2o_glm&quot; &quot;Lrnr_h2o_grid&quot; [7] &quot;Lrnr_independent_binomial&quot; &quot;Lrnr_mean&quot; [9] &quot;Lrnr_multivariate&quot; &quot;Lrnr_optim&quot; [11] &quot;Lrnr_randomForest&quot; &quot;Lrnr_ranger&quot; [13] &quot;Lrnr_rpart&quot; &quot;Lrnr_solnp&quot; [15] &quot;Lrnr_svm&quot; &quot;Lrnr_xgboost&quot; Also note that since the corresponding blip will be vector valued, with a column for each additional level of treatment. As such, we need to initialize a multivariate learners with the the helper function create_mv_learners that takes a list of initialized learners as input. We make the above explicit with respect to standard notation by bundling the ensemble learners into a list object below: # specify outcome and treatment regressions and create learner list learner_list &lt;- list(Y = Q_learner, A = g_learner, B = b_learner) The learner_list object above specifies the role that each of the ensemble learners we’ve generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest. In particular, it makes explicit the fact that our Y is used in fitting the outcome regression while our A is used in fitting our treatment mechanism regression, and finally B is used in fitting the blip function. 4.7.3 Learning the Mean Outcome under the Optimal Rule with Q-learning Here we outline how to use tmle3mopttx package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use tmle3_mopttx_Q instead of tmle3_mopttx_blip_revere in order to indicate that we want to use Q-learning instead of TMLE. # initialize a tmle specification tmle_spec_Q &lt;- tmle3_mopttx_Q(maximize = TRUE) # Define data: tmle_task &lt;- tmle_spec_Q$make_tmle_task(data, node_list) # Define likelihood: initial_likelihood &lt;- tmle_spec_Q$make_initial_likelihood(tmle_task, learner_list) #Estimate the parameter: Q_learning(tmle_spec_Q, initial_likelihood, tmle_task) [1] 0.4567778 4.7.4 Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle3_mopttx_blip_revere. We specify the argument V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;) when initializing the tmle3_Spec object in order to communicate that we’re interested in learning a rule dependent on V covariates. We also need to specify the type of pseudo-blip we will use in this estimation problem, and finally the list of learners used to estimate the blip function. # initialize a tmle specification tmle_spec &lt;- tmle3_mopttx_blip_revere(V = c(&quot;W1&quot;, &quot;W2&quot;, &quot;W3&quot;, &quot;W4&quot;), type = &quot;blip2&quot;, b_learner = learner_list$B, maximize = TRUE, complex = TRUE) As seen above, the tmle3_mopttx_blip_revere specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). In initializing the specification for the TMLE of our parameter of interest, we have specified the set of covariates the rule depends on (\\(V\\)), the type of pseudo-blip to use (“type”), and the learners used for estimating the pseudo-blip. In addition, we need to specify whether we want to maximize the mean outcome under the rule (“maximize=TRUE”), and whether we want to estimate the rule under all the covariates \\(V\\) provided by the user. If FALSE, tmle3mopttx will instead consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the subsets of \\(V\\). As such, while the user might have provided a full set of collected covariates as input for \\(V\\), it is possible that the true rule only depends on a subset of the set provided by the user. In that case, our returned mean under the optimal individualized rule will be based on the smaller subset. # fit the TML estimator fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.493051 0.5932681 0.02504458 0.5441817 0.6423546 psi_transformed lower_transformed upper_transformed 1: 0.5932681 0.5441817 0.6423546 4.7.5 Extensions: Simpler Rules 4.8 Extensions: Variable Importance Analysis with Optimal Individualized Interventions 4.9 Exercises 4.9.1 Basics/Review 4.9.2 Using the Ideas 4.9.3 Advanced References "],
["stochastic-treatment-regimes.html", "Chapter 5 Stochastic Treatment Regimes 5.1 Learning Objectives 5.2 Introduction to Stochastic Interventions 5.3 Background on Stochastic Interventions 5.4 Data Structure and Notation 5.5 Defining the Causal Effect of a Stochastic Intervention 5.6 Interpreting the Causal Effect of a Stochastic Intervention 5.7 Evaluating the Causal Effect of a Stochastic Intervention 5.8 Extensions: Variable Importance Analysis with Stochastic Interventions 5.9 Exercises", " Chapter 5 Stochastic Treatment Regimes Nima Hejazi, Jeremy Coyle, Mark van der Laan Updated: 2019-03-27 5.1 Learning Objectives … … … … … 5.2 Introduction to Stochastic Interventions Stochastic treatment regimes present a relatively simple manner in which to assess the effects of continuous treatments by way of parameters that examine the effects induced by the counterfactual shifting of the observed values of a treatment of interest. Here, we present an implementation of a new algorithm for computing targeted minimum loss-based estimates of treatment shift parameters defined based on a shifting function \\(d(A,W)\\). For a technical presentation of the algorithm, the interested reader is invited to consult Díaz and van der Laan (2018). For additional background on Targeted Learning and previous work on stochastic treatment regimes, please consider consulting van der Laan and Rose (2011), van der Laan and Rose (2018), and Díaz and van der Laan (2012). 5.3 Background on Stochastic Interventions TODO 5.4 Data Structure and Notation Consider \\(n\\) observed units \\(O_1, \\ldots, O_n\\), where each random variable \\(O = (W, A, Y)\\) corresponds to a single observational unit. As discussed before, \\(W\\) are baseline covariates, \\(A\\) is a continuous-valued intervention, and \\(Y\\) an outcome of interest. We will consider a simple stochastic intervention that considers counterfactual interventions defined through scalar shifts of the observed/natural value of the intervention \\(A\\). We’ll start by considering a simple additive shift \\(d(a,w) = a + \\delta\\), assuming support a.e. of \\(\\mathbb{P}(A \\mid W)\\). To ease violations of the positivity assumption, we may consider extensions where \\(a \\leq u(w) - \\delta\\) or \\(d(a, w) = a\\) if \\(a \\geq u(w) - \\delta\\). 5.5 Defining the Causal Effect of a Stochastic Intervention Likelihood Factorization for the Full Data: Let \\(q_{0, Y}\\) be the conditional density of \\(Y\\) given \\((A, W)\\) wrt dominating measure \\(\\xi\\). Let \\(q_{0, A}\\) be the conditional density of \\(A\\) given \\(W\\) wrt dominating measure \\(\\mu\\). Let \\(q_{0, W}\\) be the density of \\(W\\) wrt dominating measure \\(\\nu\\). Then, for \\(p_0^O\\), density of \\(O\\) wrt the product measure, density evaluated on a particular observation \\(o\\): \\[\\begin{equation*}\\label{likelihood_factorization} p_0^O(x) = q^O_{0,Y}(y \\mid A = a, W = w) q^O_{0,A}(a \\mid W = w) q^O_{0,W}(w). \\end{equation*}\\] Use a nonparametric structural equation model (NPSEM) to describe generation of \\(O\\) Pearl (2009), specifically \\[\\begin{align*} W &amp;= f_W(U_W) \\\\ A &amp;= f_A(W, U_A) \\\\ Y &amp;= f_Y(A, W, U_Y) \\end{align*}\\] NPSEM parameterizes \\(p_0^O\\) in terms of the distribution of RVs \\((O, U)\\) modeled by this system of equations. Implies a model for the distribution of counterfactual RVs generated by interventions on the data-generating process. Notation: let \\(f_W\\), \\(f_A\\), \\(f_Y\\) be deterministic functions, and \\(U_W\\), \\(U_A\\), \\(U_Y\\) exogenous RVs. modify the value \\(A\\) would naturally assume, \\(f_A(W, U_A)\\), by drawing from a modified intervention distribution \\(G^{\\star}(\\cdot \\mid W)\\) so that the new value \\(A^{\\star} \\sim G^{\\star}(\\cdot \\mid W)\\). This generates a counterfactual RV, with distribution \\(P_{0}^d\\), \\(Y_{d(A, W)} := f_Y(d(A,W), W, U_Y) \\equiv Y_{G^{\\star}} := f_Y(A^{\\star}, W, U_Y)\\). We estimate \\(\\psi_{0, d} := \\mathbb{E}_{P_0^d}\\{Y_{d(A,W)}\\}\\), mean of \\(Y_{d(A, W)}\\). Starts with Mark and Ivan’s simple stochastic shift. Extensions to modified treatment policies. The new value of \\(A\\) may be denoted \\(A^{\\star} \\sim G^{\\star}(\\cdot \\mid W)\\), where \\(A^{\\star} = d(W, U^{\\star})\\) for a rule \\(d\\) and random error \\(U^{\\star}\\). 5.5.0.1 Literature: Díaz and van der Laan (2012) Evaluate outcome under an altered — e.g., \\(P_{\\delta}(g_0)(A = a \\mid W) = g_0(a - \\delta(W) \\mid W)\\). Identification conditions for a statistical parameter of the counterfactual outcome \\(\\psi_{0,d}\\) under such an intervention. Show that the causal quantity of interest \\(\\E_0 \\{Y_{d(A, W)}\\}\\) is identified by a functional of the distribution of \\(O\\): \\[\\begin{align*}\\label{eqn:identification2012} \\psi_{0,d} = \\int_{\\mathcal{W}} \\int_{\\mathcal{A}} &amp; \\mathbb{E}_{P_0} \\{Y \\mid A = d(a, w), W = w\\} \\cdot \\\\ &amp;q_{0, A}^O(a \\mid W = w) \\cdot q_{0, W}^O(w) d\\mu(a)d\\nu(w) \\end{align*}\\] Provides a derivation based on the efficient influence function (EIF) with respect to the nonparametric model \\(\\mathcal{M}\\). The identification result allows us to write down the causal quantity of interest in terms of a functional of the observed data. Key innovation: loosening standard assumptions through a change in the observed intervention mechanism. Problem: globally altering an intervention mechanism does not necessarily respect individual characteristics. The authors build IPW, A-IPW, and TML estimators, comparing the three different approaches. IMPORTANT: gives the g-computation formula for identification of this estimator from the observed data structure. 5.5.0.2 Literature: Díaz and van der Laan (2018) Builds on the original proposal, accommodating shifts \\(d(A,W)\\) proposed after their earlier work. To protect against positivity violations, considers a specific shifting mechanism: \\[\\begin{equation*}\\label{shift_intervention} d(a, w) = \\begin{cases} a + \\delta, &amp; a + \\delta &lt; u(w) \\\\ a, &amp; \\text{otherwise} \\end{cases} \\end{equation*}\\] Proposes an improved “1-TMLE” algorithm, with a single auxiliary (“clever”) covariate for constructing the TML estimator. Identification: From Causal Inference to Statistics (Assumption 1) Consistency: \\(Y^{d(a_i, w_i)}_i = Y_i\\) in the event \\(A_i = d(a_i, w_i)\\), for \\(i = 1, \\ldots, n\\) (Assumption 2) SUTVA: \\(Y^{d(a_i, w_i)}_i\\) does not depend on \\(d(a_j, w_j)\\) for \\(i = 1, \\ldots, n\\) and \\(j \\neq i\\), or lack of interference (Rubin 1978, 1980) (Assumption 3) Strong ignorability: \\(A_i \\indep Y^{d(a_i, w_i)}_i \\mid W_i\\), for \\(i = 1, \\ldots, n\\) (Assumption 4) Positivity (or overlap): \\(a_i \\in \\mathcal{A} \\implies d(a_i, w_i) \\in \\mathcal{A}\\) for all \\(w \\in \\mathcal{W}\\), where \\(\\mathcal{A}\\) denotes the support of \\(A \\mid W = w_i \\quad \\forall i = 1, \\ldots n\\) Semiparametric-Efficient Estimation - Semiparametric-efficient estimation through solving the efficient influence function estimating equation wrt \\(\\M\\). - Statistical target parameter: \\(\\Psi(P_0) = \\mathbb{E}_{P_0}{\\overline{Q}(d(A, W), W)}\\) - For which the efficient influence function (EIF) is \\[\\begin{equation*} D(P_0)(x) = H(a, w)({y - \\overline{Q}(a, w)}) + \\overline{Q}(d(a, w), w) - \\Psi(P_0) \\end{equation*}\\] - The auxiliary covariate \\(H(a,w)\\) may be expressed \\[\\begin{equation*} H(a,w) = \\mathbb{I}(a + \\delta &lt; u(w)) \\frac{g_0(a - \\delta \\mid w)} {g_0(a \\mid w)} + \\mathbb{I}(a + \\delta \\geq u(w)) \\end{equation*}\\] - The auxiliary covariate simplifies when the treatment is in the limits (conditional on \\(W\\)) — i.e., for \\(A_i \\in (u(w) - \\delta, u(w))\\), then we have \\(H(a,w) = \\frac{g_0(a - \\delta \\mid w)}{g_0(a \\mid w)} + 1\\). - Need to explicitly remind the audience what \\(u(w)\\) is again. It has only appeared once at this point, and only been mentioned in passing. Asymptotic linearity: \\[\\begin{equation*} \\Psi(P_n^{\\star}) - \\Psi(P_0) = \\frac{1}{n} \\sum_{i = 1}^{n} D(P_0)(X_i) + o_P\\left(\\frac{1}{\\sqrt{n}}\\right) \\end{equation*}\\] Gaussian limiting distribution: \\[\\begin{equation*} \\sqrt{n}(\\Psi(P_n^{\\star}) - \\Psi(P_0)) \\to N(0, Var(D(P_0)(O))) \\end{equation*}\\] Statistical inference: \\[\\begin{equation*} \\text{Wald-type CI}: \\Psi(P_n^{\\star}) \\pm z_{\\alpha} \\cdot \\frac{\\sigma_n}{\\sqrt{n}}, \\end{equation*}\\] where \\(\\sigma_n^2\\) is computed directly via \\(\\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\cdot)(O_i)\\). Under the additional condition that the remainder term \\(R(\\hat{P}^*, P_0)\\) decays as \\(o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\) we have that \\(\\Psi_n - \\Psi_0 = (P_n - P_0) \\cdot D(P_0) + o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\) which, by a central limit theorem, establishes a Gaussian limiting distribution for the estimator, with variance \\(V(D(P_0))\\), the variance of the efficient influence function when \\(\\Psi\\) admits an asymptotically linear representation. The above implies that \\(\\Psi_n\\) is a \\(\\sqrt{n}\\)-consistent estimator of \\(\\Psi\\), that it is asymptotically normal (as given above), and that it is locally efficient. This allows us to build Wald-type confidence intervals, where \\(\\sigma_n^2\\) is an estimator of \\(V(D(P_0))\\). The estimator \\(\\sigma_n^2\\) may be obtained using the bootstrap or computed directly via \\(\\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\bar{Q}_n^*, g_n)(O_i)\\) We obtain semiparametric-efficient estimation and robust inference in the nonparametric model \\(\\M\\) by solving the efficient influence function. If \\(D(\\bar{Q}_n^*, g_n)\\) converges to \\(D(P_0)\\) in \\(L_2(P_0)\\) norm. The size of the class of functions \\(\\bar{Q}_n^*\\) and \\(g_n\\) is bounded (technically, \\(\\exists \\mathcal{F}\\) st \\(D(\\bar{Q}_n^*, g_n) \\in \\mathcal{F}\\) whp, where \\(\\mathcal{F}\\) is a Donsker class) Construct initial estimators \\(g_n\\) of \\(g_0(A, W)\\) and \\(Q_n\\) of \\(\\overline{Q}_0(A, W)\\), perhaps using data-adaptive regression techniques. For each observation \\(i\\), compute an estimate \\(H_n(a_i, w_i)\\) of the auxiliary covariate \\(H(a_i,w_i)\\). Estimate the parameter \\(\\epsilon\\) in the logistic regression model \\[ \\text{logit}\\overline{Q}_{\\epsilon, n}(a, w) = \\text{logit}\\overline{Q}_n(a, w) + \\epsilon H_n(a, w),\\] or an alternative regression model incorporating weights. Compute TML estimator \\(\\Psi_n\\) of the target parameter, defining update \\(\\overline{Q}_n^{\\star}\\) of the initial estimate \\(\\overline{Q}_{n, \\epsilon_n}\\): \\[\\begin{equation*}\\label{tmle} \\Psi_n = \\Psi(P_n^{\\star}) = \\frac{1}{n} \\sum_{i = 1}^n \\overline{Q}_n^{\\star}(d(A_i, W_i), W_i). \\end{equation*}\\] We recommend using nonparametric methods for the initial estimators, as consistent estimation is necessary for efficiency of the estimator \\(\\Psi_n\\). Intuition for the submodel fluctuation? 5.5.0.3 Literature: Haneuse and Rotnitzky (2013) Characterization of stochastic interventions as (MTPs). Assumption of allows for the intervention distribution of any MTP to be recovered: \\[\\begin{equation*} g_{0, \\delta}(a \\mid w) = \\sum_{j = 1}^{J(w)} I_{\\delta, j} \\{h_j(a, w), w\\} g_0\\{h_j(a, w) \\mid w\\} h^{\\prime}_j(a,w) \\end{equation*}\\] Such intervention policies account for the natural value of the intervention \\(A\\) directly yet are interpretable as the imposition of an altered intervention mechanism. Identification conditions for assessing the parameter of interest under such interventions appear technically complex (at first). Shifts of the form \\(d(A,W)\\) are considerably more interesting since these are realistic intervention policies. Example: consider an individual with an extremely high immune response but whose baseline covariates \\(W\\) suggest we shift the response still higher. Such a shift may not be biologically plausible (impossible, even) but we cannot account for this if the shift is only a function of \\(W\\). The authors build IPW, outcome regression, and non-iterative doubly robust estimators, as well as an approach based on MSMs. Piecewise smooth invertibility: This assumption ensures that we can use the change of variable formula when computing integrals over \\(A\\) and it is useful to study the estimators that we propose in this paper. 5.5.0.4 Literature: Young, Hernán, and Robins (2014) Establishes equivalence between g-formula when proposed intervention depends on natural value and when it does not. This equivalence leads to a sufficient positivity condition for estimating the counterfactual mean under MTPs via the same statistical functional studied in . Extends earlier identification results, providing a way to use the same statistical functional to assess \\(\\mathbb{E} Y_{d(A,W)}\\) or \\(\\mathbb{E} Y_{d(W)}\\). The authors also consider limits on implementing shifts \\(d(A,W)\\), and address working in a longitudinal setting. 5.6 Interpreting the Causal Effect of a Stochastic Intervention TODO 5.7 Evaluating the Causal Effect of a Stochastic Intervention To start, let us load the packages we will use and set a seed for simulation: library(tidyverse) library(data.table) library(condensier) library(sl3) library(tmle3) library(tmle3shift) set.seed(429153) We need to estimate two components of the likelihood in order to… The first of these is the outcome regression, \\(\\hat{Q}_n\\), which is a simple regression of the form \\(\\mathbb{E}[Y \\mid A, W]\\). An estimate for such a quantity may be constructed using the Super Learner algorithm: # learners used for conditional expectation regression lrn_mean &lt;- Lrnr_mean$new() lrn_fglm &lt;- Lrnr_glm_fast$new() lrn_xgb &lt;- Lrnr_xgboost$new(nrounds=200) lrn_hal &lt;- Lrnr_hal9001$new() sl_lrn &lt;- Lrnr_sl$new( learners = list(lrn_mean, lrn_fglm), #, lrn_xgb, lrn_hal), metalearner = Lrnr_nnls$new() ) The second of these is an estimate of the treatment mechanism, \\(\\hat{g}_n\\), i.e., the propensity score. In the case of a continuous intervention node \\(A\\), such a quantity takes the form \\(p(A \\mid W)\\), which is a conditional density. Generally speaking, conditional density estimation is a challenging problem that has received much attention in the literature (see, for example, …). To perform conditional density estimation, we focus on approach… # learners used for conditional density regression lrn_mean_dens &lt;- Lrnr_condensier$new( nbins = 20, bin_estimator = lrn_mean, bin_method = &quot;dhist&quot; ) lrn_fglm_dens &lt;- Lrnr_condensier$new( nbins = 10, bin_estimator = lrn_fglm, bin_method = &quot;dhist&quot; ) lrn_xgb_dens &lt;- Lrnr_condensier$new( nbins = 5, bin_estimator = lrn_xgb, bin_method = &quot;dhist&quot; ) sl_lrn_dens &lt;- Lrnr_sl$new( learners = list(lrn_mean_dens, lrn_fglm_dens, lrn_xgb_dens), metalearner = Lrnr_solnp_density$new() ) # specify outcome and treatment regressions and create learner list Q_learner &lt;- sl_lrn g_learner &lt;- sl_lrn_dens learner_list &lt;- list(Y = Q_learner, A = g_learner) The learner_list object above specifies the role that each of the ensemble learners we have generated is to play in computing initial estimators to be used in building a TMLE for the parameter of interest here. In particular, it makes explicit the fact that our Q_learner is used in fitting the outcome regression while our g_learner is used in estimating the treatment mechanism. 5.7.1 Simulate Data # simulate simple data for tmle-shift sketch n_obs &lt;- 1000 # number of observations tx_mult &lt;- 2 # multiplier for the effect of W = 1 on the treatment ## baseline covariates -- simple, binary W &lt;- replicate(2, rbinom(n_obs, 1, 0.5)) ## create treatment based on baseline W A &lt;- rnorm(n_obs, mean = tx_mult * W, sd = 1) ## create outcome as a linear function of A, W + white noise Y &lt;- rbinom(n_obs, 1, prob = plogis(A + W)) # organize data and nodes for tmle3 data &lt;- data.table(W, A, Y) setnames(data, c(&quot;W1&quot;, &quot;W2&quot;, &quot;A&quot;, &quot;Y&quot;)) node_list &lt;- list(W = c(&quot;W1&quot;, &quot;W2&quot;), A = &quot;A&quot;, Y = &quot;Y&quot;) head(data) W1 W2 A Y 1: 1 1 3.5806529 1 2: 1 0 3.2071846 1 3: 1 1 1.0358382 1 4: 0 0 -0.6578495 1 5: 1 1 3.0199033 1 6: 1 1 2.7803127 1 The above composes our observed data structure \\(O = (W, A, Y)\\). To formally express this fact using the tlverse grammar introduced by the tmle3 package, we create a single data object and specify the functional relationships between the nodes in the directed acyclic graph (DAG) via nonparametric structural equation models (NPSEMs), reflected in the node list that we set up: We now have an observed data structure (data) and a specification of the role that each variable in the data set plays as the nodes in a DAG. To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_val = 0.5 when initializing the tmle3_Spec object to communicate that we’re interested in a shift of \\(0.5\\) on the scale of the treatment \\(A\\) – that is, we specify \\(\\delta = 0.5\\) (note that this is an arbitrarily chosen value for this example). # initialize a tmle specification tmle_spec &lt;- tmle_shift(shift_val = 0.5, shift_fxn = shift_additive_bounded, shift_fxn_inv = shift_additive_bounded_inv) As seen above, the tmle_shift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 5.7.2 Targeted Estimation of Stochastic Interventions Effects tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1845.0103 Pars: 0.9513029795 0.0486969185 0.0000001021 Iter: 2 fn: 1845.0103 Pars: 0.95130300211 0.04869694590 0.00000005199 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower upper 1: TSM E[Y_{A=NULL}] 0.7977323 0.7948962 0.01189624 0.77158 0.8182124 psi_transformed lower_transformed upper_transformed 1: 0.7948962 0.77158 0.8182124 The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.7.3 Statistical Inference for Targeted Maximum Likelihood Estimates Recall that the asymptotic distribution of TML estimators has been studied thoroughly: \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(\\bar{Q}_n^*, g_n) + R(\\hat{P}^*, P_0),\\] which, provided the following two conditions: If \\(D(\\bar{Q}_n^*, g_n)\\) converges to \\(D(P_0)\\) in \\(L_2(P_0)\\) norm, and the size of the class of functions considered for estimation of \\(\\bar{Q}_n^*\\) and \\(g_n\\) is bounded (technically, \\(\\exists \\mathcal{F}\\) st \\(D(\\bar{Q}_n^*, g_n) \\in \\mathcal{F}\\) whp, where \\(\\mathcal{F}\\) is a Donsker class), readily admits the conclusion that \\(\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + R(\\hat{P}^*, P_0)\\). Under the additional condition that the remainder term \\(R(\\hat{P}^*, P_0)\\) decays as \\(o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\) we have that \\[\\psi_n - \\psi_0 = (P_n - P_0) \\cdot D(P_0) + o_P \\left( \\frac{1}{\\sqrt{n}} \\right),\\] which, by a central limit theorem, establishes a Gaussian limiting distribution for the estimator: \\[\\sqrt{n}(\\psi_n - \\psi) \\to N(0, V(D(P_0))),\\] where \\(V(D(P_0))\\) is the variance of the efficient influence curve (canonical gradient) when \\(\\psi\\) admits an asymptotically linear representation. The above implies that \\(\\psi_n\\) is a \\(\\sqrt{n}\\)-consistent estimator of \\(\\psi\\), that it is asymptotically normal (as given above), and that it is locally efficient. This allows us to build Wald-type confidence intervals in a straightforward manner: \\[\\psi_n \\pm z_{\\alpha} \\cdot \\frac{\\sigma_n}{\\sqrt{n}},\\] where \\(\\sigma_n^2\\) is an estimator of \\(V(D(P_0))\\). The estimator \\(\\sigma_n^2\\) may be obtained using the bootstrap or computed directly via the following \\[\\sigma_n^2 = \\frac{1}{n} \\sum_{i = 1}^{n} D^2(\\bar{Q}_n^*, g_n)(O_i)\\] Having now re-examined these facts, let’s simply examine the results of computing our TML estimator: 5.8 Extensions: Variable Importance Analysis with Stochastic Interventions 5.8.1 Defining a grid of counterfactual interventions In order to specify a grid of shifts \\(\\delta\\) to be used in defining a set of stochastic intervention policies in an a priori manner, let us consider an arbitrary scalar \\(\\delta\\) that defines a counterfactual outcome \\(\\psi_n = Q_n(d(A, W), W)\\), where, for simplicity, let \\(d(A, W) = A + \\delta\\). A simplified expression of the auxiliary covariate for the TMLE of \\(\\psi\\) is \\(H_n = \\frac{g^*(a \\mid w)}{g(a \\mid w)}\\), where \\(g^*(a \\mid w)\\) defines the treatment mechanism with the stochastic intervention implemented. Then, to ascertain whether a given choice of the shift \\(\\delta\\) is admissable (in the sense of avoiding violations of the positivity assumption), let there be a bound \\(C(\\delta) = \\frac{g^*(a \\mid w)}{g(a \\mid w)} &lt; M\\), where \\(g^*(a \\mid w)\\) is a function of \\(\\delta\\) in part, and \\(M\\) is a potentially user-specified upper bound of \\(C(\\delta)\\). Then, \\(C(\\delta)\\) is a measure of the influence of a given observation (under a bound of the conditional densities), which provides a way to limit the maximum influence of a given observation through a choice of the shift \\(\\delta\\). We formalize and extend the procedure to determine an acceptable set of values for the shift \\(\\delta\\) in the sequel. Specifically, let there be a shift \\(d(A, W) = A + \\delta(A, W)\\), where the shift \\(\\delta(A, W)\\) is defined as \\[\\begin{equation} \\delta(a, w) = \\begin{cases} \\delta, &amp; \\delta_{\\text{min}}(a,w) \\leq \\delta \\leq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{max}}(a,w), &amp; \\delta \\geq \\delta_{\\text{max}}(a,w) \\\\ \\delta_{\\text{min}}(a,w), &amp; \\delta \\leq \\delta_{\\text{min}}(a,w) \\\\ \\end{cases}, \\end{equation}\\] where \\[\\delta_{\\text{max}}(a, w) = \\text{argmax}_{\\left\\{\\delta \\geq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}\\] and \\[\\delta_{\\text{min}}(a, w) = \\text{argmin}_{\\left\\{\\delta \\leq 0, \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)} \\leq M \\right\\}} \\frac{g(a - \\delta \\mid w)}{g(a \\mid w)}.\\] The above provides a strategy for implementing a shift at the level of a given observation \\((a_i, w_i)\\), thereby allowing for all observations to be shifted to an appropriate value – whether \\(\\delta_{\\text{min}}\\), \\(\\delta\\), or \\(\\delta_{\\text{max}}\\). 5.8.2 Initializing vimshift through its tmle3_Spec To start, we will initialize a specification for the TMLE of our parameter of interest (called a tmle3_Spec in the tlverse nomenclature) simply by calling tmle_shift. We specify the argument shift_grid = seq(-1, 1, by = 1) when initializing the tmle3_Spec object to communicate that we’re interested in assessing the mean counterfactual outcome over a grid of shifts -1, 0, 1 on the scale of the treatment \\(A\\) (note that the numerical choice of shift is an arbitrarily chosen set of values for this example). # what&#39;s the grid of shifts we wish to consider? delta_grid &lt;- seq(-1, 1, 1) # initialize a tmle specification tmle_spec &lt;- tmle_vimshift_delta(shift_grid = delta_grid, max_shifted_ratio = 2) As seen above, the tmle_vimshift specification object (like all tmle3_Spec objects) does not store the data for our specific analysis of interest. Later, we’ll see that passing a data object directly to the tmle3 wrapper function, alongside the instantiated tmle_spec, will serve to construct a tmle3_Task object internally (see the tmle3 documentation for details). 5.8.3 Targeted Estimation of Stochastic Interventions Effects One may walk through the step-by-step procedure for fitting the TML estimator of the mean counterfactual outcome under each shift in the grid, using the machinery exposed by the tmle3 R package. One may invoke the tmle3 wrapper function (a user-facing convenience utility) to fit the series of TML estimators (one for each parameter defined by the grid delta) in a single function call: tmle_fit &lt;- tmle3(tmle_spec, data, node_list, learner_list) Iter: 1 fn: 1844.2284 Pars: 0.96656215268 0.03343778776 0.00000005682 Iter: 2 fn: 1844.2284 Pars: 0.966562195572 0.033437800382 0.000000004046 solnp--&gt; Completed in 2 iterations tmle_fit A tmle3_Fit that took 1 step(s) type param init_est tmle_est se lower 1: TSM E[Y_{A=NULL}] 0.6128645 0.6127271 0.015541581 0.5822662 2: TSM E[Y_{A=NULL}] 0.7389799 0.7390000 0.013895038 0.7117662 3: TSM E[Y_{A=NULL}] 0.8489662 0.8495258 0.009815749 0.8302873 4: MSM_linear MSM(intercept) 0.7333998 0.7335228 0.012680492 0.7086695 5: MSM_linear MSM(slope) 0.1169330 0.1173696 0.004617009 0.1083205 upper psi_transformed lower_transformed upper_transformed 1: 0.6431881 0.6127271 0.5822662 0.6431881 2: 0.7662338 0.7390000 0.7117662 0.7662338 3: 0.8687643 0.8495258 0.8302873 0.8687643 4: 0.7583761 0.7335228 0.7086695 0.7583761 5: 0.1264188 0.1173696 0.1083205 0.1264188 Remark: The print method of the resultant tmle_fit object conveniently displays the results from computing our TML estimator. 5.8.4 Inference with Marginal Structural Models In the directly preceding section, we consider estimating the mean counterfactual outcome \\(\\psi_n\\) under several values of the intervention \\(\\delta\\), taken from the aforementioned \\(\\delta\\)-grid. We now turn our attention to an approach for obtaining inference on a single summary measure of these estimated quantities. In particular, we propose summarizing the estimates \\(\\psi_n\\) through a marginal structural model (MSM), obtaining inference by way of a hypothesis test on a parameter of this working MSM. For a data structure \\(O = (W, A, Y)\\), let \\(\\psi_{\\delta}(P_0)\\) be the mean outcome under a shift \\(\\delta\\) of the treatment, so that we have \\(\\vec{\\psi}_{\\delta} = (\\psi_{\\delta}: \\delta)\\) with corresponding estimators \\(\\vec{\\psi}_{n, \\delta} = (\\psi_{n, \\delta}: \\delta)\\). Further, let \\(\\beta(\\vec{\\psi}_{\\delta}) = \\phi((\\psi_{\\delta}: \\delta))\\). For a given MSM \\(m_{\\beta}(\\delta)\\), we have that \\[\\beta_0 = \\text{argmin}_{\\beta} \\sum_{\\delta}(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta))^2 h(\\delta),\\] which is the solution to \\[u(\\beta, (\\psi_{\\delta}: \\delta)) = \\sum_{\\delta}h(\\delta) \\left(\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta) \\right) \\frac{d}{d\\beta} m_{\\beta}(\\delta) = 0.\\] This then leads to the following expansion \\[\\beta(\\vec{\\psi}_n) - \\beta(\\vec{\\psi}_0) \\approx -\\frac{d}{d\\beta} u(\\beta_0, \\vec{\\psi}_0)^{-1} \\frac{d}{d\\psi} u(\\beta_0, \\psi_0)(\\vec{\\psi}_n - \\vec{\\psi}_0),\\] where we have \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta) -\\sum_{\\delta} h(\\delta) m_{\\beta}(\\delta) \\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta),\\] which, in the case of an MSM that is a linear model (since \\(\\frac{d^2}{d\\beta^2} m_{\\beta}(\\delta) = 0\\)), reduces simply to \\[\\frac{d}{d\\beta} u(\\beta, \\psi) = -\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\frac{d}{d\\beta} m_{\\beta}(\\delta),\\] and \\[\\frac{d}{d\\psi}u(\\beta, \\psi)(\\psi_n - \\psi_0) = \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) (\\psi_n - \\psi_0)(\\delta),\\] which we may write in terms of the efficient influence function (EIF) of \\(\\psi\\) by using the first order approximation \\((\\psi_n - \\psi_0)(\\delta) = \\frac{1}{n}\\sum_{i = 1}^n \\text{EIF}_{\\psi_{\\delta}}(O_i)\\), where \\(\\text{EIF}_{\\psi_{\\delta}}\\) is the efficient influence function (EIF) of \\(\\vec{\\psi}\\). Now, say, \\(\\vec{\\psi} = (\\psi(\\delta): \\delta)\\) is d-dimensional, then we may write the efficient influence function of the MSM parameter \\(\\beta\\) (assuming a linear MSM) as follows \\[\\text{EIF}_{\\beta}(O) = \\left(\\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta)^t \\right)^{-1} \\cdot \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} m_{\\beta}(\\delta) \\text{EIF}_{\\psi_{\\delta}}(O),\\] where the first term is of dimension \\(d \\times d\\) and the second term is of dimension \\(d \\times 1\\). In an effort to generalize still further, consider the case where \\(\\psi_{\\delta}(P_0) \\in (0, 1)\\) – that is, \\(\\psi_{\\delta}(P_0)\\) corresponds to the probability of some event of interest. In such a case, it would be more natural to consider a logistic MSM \\[m_{\\beta}(\\delta) = \\frac{1}{1 + \\exp(-f_{\\beta}(\\delta))},\\] where \\(f_{\\beta}\\) is taken to be linear in \\(\\beta\\) (e.g., \\(f_{\\beta} = \\beta_0 + \\beta_1 \\delta + \\ldots\\)). In such a case, we have the parameter of interest \\[\\beta_0 = \\text{argmax}_{\\beta} \\sum_{\\delta} \\left(\\psi_{\\delta}(P_0) \\text{log} m_{\\beta}(\\delta) + (1 - \\psi_{\\delta}(P_0))\\log(1 - m_{\\beta}(\\delta))\\right)h(\\delta),\\] where \\(\\beta_0\\) solves the following \\[ \\sum_{\\delta} h(\\delta) \\frac{d}{d\\beta} f_{\\beta}(\\delta) (\\psi_{\\delta}(P_0) - m_{\\beta}(\\delta)) = 0.\\] Inference from a working MSM is rather straightforward. To wit, the limiting distribution for \\(m_{\\beta}(\\delta)\\) may be expressed \\[\\sqrt{n}(\\beta_n - \\beta_0) \\to N(0, \\Sigma),\\] where \\(\\Sigma\\) is the empirical covariance matrix of \\(\\text{EIF}_{\\beta}(O)\\). tmle_fit$summary[4:5, ] type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.7333998 0.7335228 0.012680492 0.7086695 2: MSM_linear MSM(slope) 0.1169330 0.1173696 0.004617009 0.1083205 upper psi_transformed lower_transformed upper_transformed 1: 0.7583761 0.7335228 0.7086695 0.7583761 2: 0.1264188 0.1173696 0.1083205 0.1264188 5.8.4.1 Directly Targeting the MSM Parameter \\(\\beta\\) Note that in the above, a working MSM is fit to the individual TML estimates of the mean counterfactual outcome under a given value of the shift \\(\\delta\\) in the supplied grid. The parameter of interest \\(\\beta\\) of the MSM is asymptotically linear (and, in fact, a TML estimator) as a consequence of its construction from individual TML estimators. In smaller samples, it may be prudent to perform a TML estimation procedure that targets the parameter \\(\\beta\\) directly, as opposed to constructing it from several independently targeted TML estimates. An approach for constructing such an estimator is proposed in the sequel. Suppose a simple working MSM \\(\\mathbb{E}Y_{g^0_{\\delta}} = \\beta_0 + \\beta_1 \\delta\\), then a TML estimator targeting \\(\\beta_0\\) and \\(\\beta_1\\) may be constructed as \\[\\overline{Q}_{n, \\epsilon}(A,W) = \\overline{Q}_n(A,W) + \\epsilon (H_1(g), H_2(g),\\] for all \\(\\delta\\), where \\(H_1(g)\\) is the auxiliary covariate for \\(\\beta_0\\) and \\(H_2(g)\\) is the auxiliary covariate for \\(\\beta_1\\). To construct a targeted maximum likelihood estimator that directly targets the parameters of the working marginal structural model, we may use the tmle_vimshift_msm Spec (instead of the tmle_vimshift_delta Spec that appears above): # initialize a tmle specification tmle_msm_spec &lt;- tmle_vimshift_msm(shift_grid = delta_grid, max_shifted_ratio = 2) # fit the TML estimator and examine the results tmle_msm_fit &lt;- tmle3(tmle_msm_spec, data, node_list, learner_list) Iter: 1 fn: 1838.4669 Pars: 0.96061554500 0.03938437967 0.00000007423 Iter: 2 fn: 1838.4668 Pars: 0.960615569450 0.039384428822 0.000000001728 solnp--&gt; Completed in 2 iterations tmle_msm_fit A tmle3_Fit that took 100 step(s) type param init_est tmle_est se lower 1: MSM_linear MSM(intercept) 0.7331760 0.7331760 0.012769216 0.7081488 2: MSM_linear MSM(slope) 0.1167797 0.1167797 0.004687733 0.1075919 upper psi_transformed lower_transformed upper_transformed 1: 0.7582032 0.7331760 0.7081488 0.7582032 2: 0.1259674 0.1167797 0.1075919 0.1259674 5.9 Exercises 5.9.1 Basics/Review TODO Set the sl3 library of algorithms for the Super Learner TODO Describe two (equivalent) ways in which the causal effects of stochastic interventions may be interpreted. 5.9.2 Using the Ideas Choose a different variable of interest (e.g., TBD) and repeat the initial analysis we performed. That is, estimate the counterfactual mean under a shift of the new variable, after standardizing the chosen variable to have zero mean and unit variance. TODO TODO What advantages, if any, are there to targeted directly the parameters of a marginal structural model? 5.9.3 Advanced How does the marginal structural model we used to summarize… TODO References "],
["references.html", "References", " References "]
]

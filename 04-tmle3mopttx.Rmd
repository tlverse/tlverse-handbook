# Optimal Individualized Treatment Regimes

_Ivana Malenica, Jeremy Coyle, Mark van der Laan_

Updated: `r Sys.Date()`

## Learning Objectives
<!--- appears as "X.1: Learning Objectives" in the book, where X is the chapter
corresponding to optimal interventions -->
1. ...
2. ...
3. ...
4. ...
5. ...

## Introduction to Optimal Individualized Interventions

The aim of precision medicine is to allow for patient specific interventions. 
In the case of categorical treatment, one opts to administer the intervention to 
individuals who will benefit from it, instead of assigning treatment on a population level. 
For example, Abacavir and Tenofovir are commonly prescribed as part of the antiretroviral therapy to Human Immunodeficiency Virus (HIV) patients. However, not all individuals benefit from the two medications 
equally. In particular, patients with renal dysfunction might further deteriorate if
prescribed Tenofovir, due to the high nephrotoxicity caused by the medication. 
While Tenofovir is still highly effective treatment option for HIV patients, in order to maximize the 
patient's well-being, it would be benefitial to prescribe Tenofovir only to individuals 
with healthy kindey function. 

This motivates a diffent type of interention, as opposed to the static exposures we 
might be used to. In particular, in this chapter we learn about dynamic or individualized 
interventions that tailor the treatment decision based on the collected covariates. 
In the statistics community such a treatment strategy is termed 
\bf{individualized treatment regime} (ITR), and the (counterfactual) population mean outcome 
under an ITR is the value of the ITR \cite{neyman1990,robins1986,pearl2009}. 
Even more, suppose one wishes to maximize the population 
mean of an outcome, where for each individual we have access to some set of measured covariates. 
This means, for example, that we can learn for which individual characteristics assigning treatment increases 
the probability of a benefitial outcome for each individual. 
An ITR with the maximal value is referred to as an optimal ITR or the \bf{optimal individualized treatment}. 
Consequently, the value of an optimal ITR is termed the optimal value, or the \bf{mean under the 
optimal individualized treatment.}

The problem of estimating the optimal individualized treatment has received much attention
in the statistics literature over the years, especially with the advancement of
precision medicine; see @murphy2003, @robins2004, @moodie2013 and @robins2014 to name a few. 
However, much of the early work depends on parametric assumptions. As such, even in a randomized trial, 
the statistical inference for the optimal individualized treatment relies on assumptions that 
are generally believed to be false, and can lead to biased results. 

In this chapter, we consider estimation of the mean outcome under the optimal individualized treatment 
where the candidate rules are restricted to depend only on user-supplied subset of the baseline covariates.
The estimation problem is addressed in a statistical model for the data distribution that is nonparametric, 
and at most places restrictions on the probability of a patient receiving treatment given covariates (as in a
randomized trial). As 
such, we don't need to make any assumptions about the relationship of the outcome with the treatment and 
covariates, or the relationship between the treatment and covariates. For a technical presentation of
the algorithm, the interested reader is invited to further consult @vanderLaanLuedtke15 and @luedtke2016super.
For additional background on Targeted Learning, please consider consulting @vdl2011targeted and
@vdl2018targeted.
   
---

## Data Structure and Notation

Suppose we observe $n$ independent and identically distributed observations of the form $O=(W,A,Y) \sim P_0$. We denote $A$ as categorical treatment, and $Y$ as the final outcome. Note that we treat $W$ as vector-valued, representing all of our collected baseline covariates. Therefore, for a single random individual $i$, we have that their observed data is $O_i$: with corresponding baseline covariates $W_i$, treatment $A_i$, and final outcome $Y_i$. We say that $O \sim P_0$, or that all data was drawn from some probability distribution $P_0$. We emphasize that we make no assumptions about the distribution of $P_0$, so that $P_0 \in \mathcal{M}$, where $\mathcal{M}$ is the fully nonparametric model. We can break the data generating distribution $P_0$ into the following parts by time ordering:

$$P_0(O) = P_0(Y|A,W)P_0(A|W)P_0(W) = Q_{Y,0}(Y|A,W)g_0(A|W)Q_{W,0}(W)$$
where $P_0(Y|A,W)=Q_{Y,0}(Y|A,W)$, $P_0(A|W)=g_0(A|W)$ and $P_0(W)=Q_{W,0}(W)$. For notational simplicity, we also define $\bar{Q}_{Y,0}(A,W) \equiv E_0[Y|A,W]$.

## Defining the Causal Effect of an Optimal Individualized Intervention

Many methods for learning an optimal rule from data have been developed. Here, we focus on the methods developed in @luedtke2016super and @vanderLaanLuedtke15; however `tmle3mopttx` also supports the widely used Q-learning approach, based on generating an estimate of $\bar{Q}_{Y,0}(A,W)$ @Sutton1998. We cover how to use the Q-learning approach in the later implementation of the vignette. 
However, we focus on the methodology outlined in @luedtke2016super and @vanderLaanLuedtke15, where we learn the optimal ITR using Super Learner @vdl2007super, and estimate its value using the cross-validated Targeted Minimum Loss-based Estimation (CV-TMLE) @cvtmle2010. Luedtke and van der Laan present three different appraches for learning the optimal rule, but `tmle3mopttx` relies on using the Super Learner to estimate the blip function (or "pseudo-blip" for categorical treatment). 
In great generality, we first need to estimate an individual treatment regime which corresponds to dynamic treatment rule ($d(V)$) that takes a subset of covariates $V \in W$ and assigns treatment. As specified in the introduction, we are also interested in the value of such a dynamic rule: $$E_0[Y_{d(V)}] = E_{0,W}[\bar{Q}_{Y,0}(A=d(V),W)]$$ which, under causal assumptions, can be interpreted as the mean outcome if (possibly contrary to fact), treatment was assigned according to the rule. The optimal rule is the rule with the maximal value: $$d_0 \equiv \text{argmax}_{d \in \mathcal{D}} E_0[Y_{d(V)}] $$
where $\mathcal{D}$ represents the set of possible rules, $d$. We note that minimization is completely ok as well, depending on the problem in hand. 

### Binary treatment

In the case of a binary treatment, a key quantity for optimal ITR is the blip function. In particular, one can show that any optimal ITR assigns treatment to individuals falling in strata in which the stratum specific average treatment effect, the blip function, is positive and does not assign treatment to individuals for which this quantity is negative. Therefore for a binary treatment, we define a blip function as $$E_0[Y_1-Y_0|V] \equiv E_0[\bar{Q}_{Y,0}(1,W) - \bar{Q}_{Y,0}(0,W) | V] $$
The note that the rule can now be derived as $d_0(V) = I(\bar{Q}_0(V) > 0)$.

In particular, we will:

1. Estimate $\bar{Q}_{Y,0}(A,W)$ and $g_0(A|W)$ using `sl3`.

2. Apply the doubly robust A-IPW transform to our outcome, where we define:

$$D_{\bar{Q},g,a}(O) \equiv \frac{I(A=a)}{g(A|W)} (Y-\bar{Q}_Y(A,W)) + \bar{Q}_Y(A=a,W),$$
Using this transform, we can define the following contrast:
$D_{\bar{Q},g}(O) = D_{\bar{Q},g,a=1}(O) - D_{\bar{Q},g,a=0}(O)$

We estimate the blip function (\bar{Q}_{0,a}(V)) by regressing $D_{\bar{Q},g}(O)$ on $V$ using `sl3`.

3. Our estimated rule is $d(V) = \text{argmax}_{a \in \mathcal{A}} \bar{Q}_{0,a}(V)$.

4. Obtain inference for the mean outcome under the optimal rule using CV-TMLE.

### Categorical treatment

In line with the approach considered for binary treatment, we extend the blip function apprach to allow for categorical treatment by estimating "pseudo-blips". We define pseudo-blips as vector valued entities where the output for a given $V$ is a vector of length equal to the number of treatment categories. As such, we define it as:
$$\bar{Q}_0^{pblip}(V) = \{\bar{Q}_{0,a}^{pblip}(V): a \in \mathcal{A} \}$$

We implement three different pseudo-blips in `tmle3mopttx`. 

1. "Blip1" corresponds to choosing a reference category of treatment, and defining the blip for all other categories relative to the specified reference. Hence we have that: $$\bar{Q}_{0,a}^{pblip-ref}(V) \equiv E_0(Y_a-Y-0|V)$$ where $Y_0$ is the specified reference category. Note that, for the case of binary treatment, this strategy reduces to the apparoach described in the previous section.

2. "Blip2" approach corresponds to defining the blip relative to the average of all categories. As such, we can define $\bar{Q}_{0,a}^{pblip-avg}(V)$ as:
$$\bar{Q}_{0,a}^{pblip-avg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{'} \in \mathcal{A}} Y_{a^{'}}|V)$$
3. "Blip3" reflects an extension of "Blip2", where the average is now a weighted average. 
$$\bar{Q}_{0,a}^{pblip-wavg}(V) \equiv E_0(Y_a- \frac{1}{n_A} \sum_{a^{'} \in \mathcal{A}} P(A=a^{'}|V)
Y_{a^{'}}|V)$$

Just like in the binary case, pseudo-blips are estimated by regressing contrasts composed using the A-IPW transform on $V$. 

## Interpreting the Causal Effect of an Optimal Individualized Intervention

TODO

## Evaluating the Causal Effect of an Optimal Individualized Intervention with Binary Treatment

TODO

## Evaluating the Causal Effect of an Optimal Individualized Intervention with Categorical Treatment

To start, let's load the packages we'll use and set a seed for simulation:

```{r setup-mopttx, message=FALSE, warning=FALSE}
library(data.table)
library(sl3)
library(tmle3)
library(tmle3mopttx)
library(devtools)
set.seed(111)
```

### Simulated Data

First, we load the simulated data. Here, our data generating distribution is of the following form:

$$W \sim \mathcal{N}(\bf{0},I_{4 \times 4})$$
$$P(A=a|W) = \frac{1}{1+\exp^{(-0.8*W_a)}}$$

$$P(Y=1|A,W) = 0.5\text{logit}^{-1}[3I(A=1)(W_1-0.5) - 3I(A=2)(2W_2+0.5) + 3I(A=3)(3W_3-0.5)] +\text{logit}^{-1}(W_2W_3)$$
```{r load sim_data}
data("data_cat")
```

The above composes our observed data structure $O = (W, A, Y)$. Note that the 
mean under the true optimal rule is $\psi=0.625$.

To formally express this fact using the `tlverse` grammar introduced by the `tmle3` package,
we create a single data object and specify the functional relationships between
the nodes in the _directed acyclic graph_ (DAG) via _nonparametric structural
equation models_ (NPSEMs), reflected in the node list that we set up:

```{r data_nodes-mopttx}
# organize data and nodes for tmle3
data <- data_cat
node_list <- list(
  W = c("W1", "W2", "W3", "W4"),
  A = "A",
  Y = "Y"
)
```

We now have an observed data structure (`data`) and a specification of the role
that each variable in the data set plays as the nodes in a DAG.

### Constructing Optimal Stacked Regressions with `sl3`

To easily incorporate ensemble machine learning into the estimation procedure,
we rely on the facilities provided in the [`sl3` R
package](https://sl3.tlverse.org). For a complete guide on using the `sl3` R
package, consider consulting https://sl3.tlverse.org, or https://tlverse.org for
the [`tlverse` ecosystem](https://github.com/tlverse), of which `sl3` is a major
part.

Using the framework provided by the [`sl3` package](https://sl3.tlverse.org),
the nuisance parameters of the TML estimator may be fit with ensemble learning,
using the cross-validation framework of the Super Learner algorithm of
@vdl2007super.

```{r sl3_lrnrs-mopttx}
#Initialize some of the learners.
#Here we use xgboost with various parameters, glm, HAL and the simle mean.
xgboost_50<-Lrnr_xgboost$new(nrounds = 50)
xgboost_100<-Lrnr_xgboost$new(nrounds = 100)
xgboost_500<-Lrnr_xgboost$new(nrounds = 500)
lrn1 <- Lrnr_mean$new()
lrn2<-Lrnr_glm_fast$new()
lrn3<-Lrnr_hal9001$new()

#Define the Q learner, which is just a regular learner:
Q_learner <- Lrnr_sl$new(
  learners = list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2),
  metalearner = Lrnr_nnls$new()
)

#Define the g learner, which is a multinomial learner:
glib <- list(
  rf <- make_learner(Lrnr_randomForest),
  xgb <- make_learner(Lrnr_xgboost),
  glmnet <- make_learner(Lrnr_glmnet),
  multinom_gf <- make_learner(Lrnr_independent_binomial, make_learner(Lrnr_glm_fast)),
  mean <- make_learner(Lrnr_mean)
)

mn_metalearner <- make_learner(Lrnr_solnp, loss_function = loss_loglik_multinomial, 
                               learner_function = metalearner_linear_multinomial)
g_learner <- make_learner(Lrnr_sl, glib, mn_metalearner)

#Define the Blip learner, which is a multivariate learner:
learners <- list(xgboost_50,xgboost_100,xgboost_500,lrn1,lrn2)
b_learner <- create_mv_learners(learners = learners)

```

As seen above, we generate three different ensemble learners that must be fit, corresponding to the learners for the outcome regression, propensity score, and the blip function. Note that we need to estimate $g_0(A|W)$ for a categorical $A$- therefore we use the multinomial Super Learner option available within the `sl3` package with learners that can address multi-class classification problems. In order to see which learners can be used to estimate $g_0(A|W)$ in `sl3`, we run the following:

```{r cat_learners}
#See which learners support multi-class classification:
sl3_list_learners(c("categorical"))
```

Also note that since the corresponding blip will be vector valued, with a column for each additional level of treatment. As such, we need to initialize a multivariate learners with the the helper function `create_mv_learners` that takes a list of initialized learners as input. 

We make the above explicit with respect to standard notation by bundling the
ensemble learners into a list object below:

```{r make_lrnr_list-mopttx}
# specify outcome and treatment regressions and create learner list
learner_list <- list(Y = Q_learner, A = g_learner, B = b_learner)
```

The `learner_list` object above specifies the role that each of the ensemble
learners we've generated is to play in computing initial estimators to be used
in building a TMLE for the parameter of interest. In particular, it makes
explicit the fact that our `Y` is used in fitting the outcome regression
while our `A` is used in fitting our treatment mechanism regression, and finally `B` is used in fitting the blip function.

### Learning the Mean Outcome under the Optimal Rule with Q-learning

Here we outline how to use `tmle3mopttx` package in order to estimate the mean under the ITR using Q-learning. As demonstrated in the previous sections, we first need to initialize a specification for the TMLE of our parameter of interest. As opposed to the previous section however, we will now use `tmle3_mopttx_Q` instead of `tmle3_mopttx_blip_revere` in order to indicate that we want to use Q-learning instead of TMLE. 

```{r spec_init_Qlearning}
# initialize a tmle specification
tmle_spec_Q <- tmle3_mopttx_Q(maximize = TRUE)

# Define data:
tmle_task <- tmle_spec_Q$make_tmle_task(data, node_list)

# Define likelihood:
initial_likelihood <- tmle_spec_Q$make_initial_likelihood(tmle_task, learner_list)

#Estimate the parameter:
Q_learning(tmle_spec_Q, initial_likelihood, tmle_task)

```

### Targeted Estimation of the Mean under the Optimal Individualized Interventions Effects

To start, we will initialize a specification for the TMLE of our parameter of
interest (called a `tmle3_Spec` in the `tlverse` nomenclature) simply by calling
`tmle3_mopttx_blip_revere`. We specify the argument `V = c("W1", "W2", "W3", "W4")`
when initializing the `tmle3_Spec` object in order to communicate that we're interested
in learning a rule dependent on `V` covariates. We also need to specify the type of 
pseudo-blip we will use in this estimation problem, and finally the list of learners 
used to estimate the blip function.

```{r spec_init}
# initialize a tmle specification
tmle_spec <- tmle3_mopttx_blip_revere(V = c("W1", "W2", "W3", "W4"), type = "blip2", b_learner = learner_list$B, maximize = TRUE, complex = TRUE)
```

As seen above, the `tmle3_mopttx_blip_revere` specification object (like all `tmle3_Spec`
objects) does _not_ store the data for our specific analysis of interest. Later,
we'll see that passing a data object directly to the `tmle3` wrapper function,
alongside the instantiated `tmle_spec`, will serve to construct a `tmle3_Task`
object internally (see the `tmle3` documentation for details).

In initializing the specification for the TMLE of our parameter of
interest, we have specified the set of covariates the rule depends on ($V$), the type of pseudo-blip to use ("type"), and the learners used for estimating the pseudo-blip. In addition, we need to specify whether we want to maximize the mean outcome under the rule ("maximize=TRUE"), and whether we want to estimate the rule under all the covariates $V$ provided by the user. If FALSE, `tmle3mopttx` will instead consider all the possible rules under a smaller set of covariates including the static rules, and optimize the mean outcome over all the subsets of $V$. As such, while the user might have provided a full set of collected covariates as input for $V$, it is possible that the true rule only depends on a subset of the set provided by the user. In that case, our returned mean under the optimal individualized rule will be based on the smaller subset.

```{r fit_tmle_auto, eval=T}
# fit the TML estimator
fit <- tmle3(tmle_spec, data, node_list, learner_list)
fit
```

### Extensions: Simpler Rules

## Extensions: Variable Importance Analysis with Optimal Individualized Interventions




---

## Exercises

### Basics/Review

### Using the Ideas

### Advanced









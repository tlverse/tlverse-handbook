# The Roadmap for Targeted Learning {#intro}

## Learning Objectives

By the end of this chapter you will be able to:
1. Translate scientific questions to statistical questions.
2. Define a statistical model based on the knowledge of the experiment that
   generated the data.
3. Identify a causal parameter as a function of the observed data distribution.
4. Explain the following assumptions, and their implications: i.i.d, positivity,

## Introduction

The roadmap of statistical learning is concerned with the translation from the
real-world data application into a mathematical and statistical formulation of
the actual estimation problem that needs to be solved. This involves data as a
random variable having a probability distribution, statistical knowledge
represented by a statistical model, statistical target parameter which
represents the question of interest, and the notion of an estimator and sampling
distribution of the estimator.

## The Roadmap

**1. Data as a random variable with a probability distribution, $O \sim P_0$.**

$$O_1, ..., O_n \simiid P_0$$

The data set we're confronted with is the result of an experiment and we can
view the data as a random variable, $O$, because if we repeat the experiment
we would have a different realization of this experiment. In particular, if we
repeat the experiment many times we could learn the probability distribution,
$P_0$, of our data. So, the observed data $O$ with probability distribution
$P_0$ are $n$ independent identically distributed (i.i.d) observations of the
random variable $O; $O_1, \ldots, O_n$. Note that i.i.d. is a real assumption
and not all data are i.i.d. There are ways to handle non-i.i.d. data such as
establishing conditional independence, stratifying the data to create sets of
identically distributed data, etc. Researchers need to be absolutely clear
about what they actually know about the distributions that generate their data.
Unfortunately, communication between statisticians and researchers often gets
lost in translation and thereby misinterpreted. This is one reason why the
roadmap is so helpful -- it truly helps with this communication!

**The empirical probability measure, $P_n$**
Once we have $n$ of such i.i.d. observations we have an empirical probability
measure, $P_n$. The empirical probability measure is an approximation of the true
probability measure $P_0$ and it allows us to learn from our data. For example, we
can define the empirical probability measure of a set, $A$, to be the proportion
of observations which end up in $A$. That is,

$$P_n(A) = \frac{1}{n}\sum_{i=1}^{n}I(O_i \in A)$$

In order to start learning something, we need to ask *``What do we know about the
probability distribution of the data?"* This brings us to Step 2.

**2. The statistical model, $P_0 \in \mathcal{M}$**

The statistical model $\mathcal{M}$ is defined by the question we asked at the
end of Step 1. It is defined as the set of possible probability distributions
for our data. Often $\mathcal{M}$ is very large because statistical knowledge
is limited so $\mathcal{M}$ is often infinite dimensional. We call this a
non-parametric statistical model.\\

Alternatively, if the probability distribution of your data is described by a
finite number of parameters then the statistical model is parametric. This
means we believe our random variable we're observing on a unit like
blood pressure has e.g. a normal distribution with mean $\mu$ and variance
$\sigma^2$.  More formally, a parametric model is defined as:

$$\mathcal{M} = \{P_{\theta} : \theta \in \mathcal{R}^d \}$$

Sadly, it is all-too-common to assume the data-generating distributions have
specific forms when such knowledge is certainly not at hand. This lack of truth
in the current culture of analysis typically trumps trying to answer the real
scientific question at hand and is supported by statements such as
“All models are wrong but some are useful,” which allow a user to make arbitrary
choices even though these choices result in different answers to the same
estimation problem. The Targeted Learning methodology does not suffer from this
selection bias since it defines the statistical model as a representation for
the true data generating distribution that produced the observed data.

Our next question becomes, *``What are we trying to learn from the data?"*
This brings us to Step 3.

**3. The statistical target parameter, $\Psi: \mathcal{M}\rightarrow\mathbb{R}$**

The statistical target parameter, $\Psi$ is defined as a mapping from the
statistical model, $\mathcal{M}$ to the parameter space (i.e., a number),
$\mathcal{R}$. It is defined by the query mentioned at the end of Step 2. Target parameters of interest represent questions, which are often causal.
Causal target parameters require identifiability, and causal models (see appendix of this chapter for more detail). \\

For example, say we observe a survival time on every subject and our question
of interest is "What's the probability that someone lives longer than five
years?" We have,

$$\Psi(P_0) = P_0(O > 5)$$

This answer to this question brings us to Step 4.

**4. The estimand, $\Psi(P_0)$**

The answer to the query asked in Step 3. This estimand is quantity we're really
trying to learn. Once we have defined $O$, $\mathcal{M}$ and $\Psi(P_0)$ we have
formally defined the statistical estimation problem.

#### After formally defining the statistical estimation problem

We use the data to estimate the estimand and hopefully the estimator has good
statistical properties to approximate the estimate. Additionally, we try to end
up with statistical inference (i.e. we try to quantify the uncertainty in our
estimator). We need statistical theory to guide us in the construction of our
estimators.

**5. The estimator, $\hat{\Psi} : \mathcal{M}_{NP} \rightarrow \mathbb{R}^d$**

To come up with a good estimand we need an estimator, an a-priori specified
algorithm defined as a mapping from the set of possible empirical distributions,
$P_n$, which live in a non-parametric statistical model, $\mathcal{M}_{NP}$
($P_n \in \mathcal{M}_{NP}$), to the parameter space for our parameter of
interest. It is a function that takes as input the observed data, a realization
of $P_n$, and gives as output a value in the parameter space.

**6. The estimate, $\hat{\Psi}(P_n)$**

The output mentioned at the end of Step 5 is defined as the estimate. It is a
function of the empirical probability distribution of the data that is an
element of the parameter space. If we plug in a realization of $P_n$ (based on
a sample size $n$ of the random variable $O$), we get back an estimate
$\hat{\Psi}(P_n)$ of the true parameter value $\Psi(P_0)$.\\

In order to have any hope of coming up with the quantification of the
uncertainty (i.e. statistical inference), we need to understand the sampling
distribution of our estimator. This brings us to step 7.

**7. Sampling distribution of $\hat{\Psi}(P_n)$**

The sampling distribution of $\hat{\Psi}(P_n)$ says that the estimator itself
is a random variable. So, if we repeat the experiment of drawing $n$
observations we would every time end up with a different realization of our
estimator and our estimator has a sampling/probability distribution. Hopefully
this sampling distribution can be theoretically validated to be approximately
normally distributed.

#### Statistical Inference

The \textbf{Central Limit Theorem} (CLT) allows us to make statements regarding
the \textit{sampling distribution of our estimator} approximating a normal
distribution when the sample size gets large enough. For large $n$ we have,

$$\hat{\Psi}(P_n) \sim N\Big( \Psi(P_0), \frac{\sigma^2}{n} \Big)$$

This permits statistical inference. Now we can quantify the uncertainty in our
estimator. For example, we can construct a 95\% confidence interval for our
estimand, $\Psi(P_0)$:

$$\hat{\Psi}(P_n) \pm 1.96 \Big( \frac{\sigma}{\sqrt{n}} \Big)$$

Note: we typically have to estimate the standard error,
$\frac{\sigma}{\sqrt{n}}$.\\

A 95\% confidence interval means that if we were to take 100 different samples
of size $n$ and compute a 95\% confidence interval for each sample then
approximately 95 of the 100 confidence intervals would contain the estimand,
$\Psi(P_0)$. More practically, this means that there is a 95\% probability
(or 95\% confidence) that the confidence interval procedure will contain the
true estimand. However, any single estimated confidence interval either will
contain the true estimand or will not.

## Summary

Data, $O$, is viewed as a random variable that has a probability distribution.
We often have $n$ units of independent identically distributed units with
probability distribution $P_0$ ($O_1, \ldots, O_n \simiid P_0$). We have
statistical knowledge about the experiment that generated this data. In other
words, we make a statement that the true data distribution $P_0$ falls in a
certain set called a statistical model, $\mathcal{M}$. Often these sets are very
large because statistical knowledge is very limited so these statistical models
are often infinite dimensional models. Our statistical query is, "What are we
trying to learn from the data?" denoted by the statistical target parameter,
$\Psi$, which maps the $P_0$ into the estimand, $\Psi(P_0)$. At this point the
statistical estimation problem is formally defined and now we will need
statistical theory to guide us in the construction of estimators. There's a lot
of statistical theory we will review in this course that, in particular, relies
on the Central Limit Theorem, allowing us to come up with estimators that are
approximately normally distributed and also allowing us to come with statistical
inference (i.e., confidence intervals).

## Appendix

### Causal models
A causal framework may be employed to formalize the experiment and enrich the
parameter of interest, or research question, by asking a causal question opposed
to a statistical (i.e., associational/relational) question. Causal graphs are
one useful tool to express what we know about the causal relations among
variables that are relevant to the question under study @pearl_causality_2000.
An illustration shows a simple causal graph, specifically a *directed acyclic
graph or DAG*, to depict the causal relations between variables with a simple
example of a binary exposure $A$, a binary outcome $Y$, and one categorical confounding variable $W$. The DAG for these relations is depicted below.

\includegraphics[width=4.0in]{CausalGraph.pdf}

The $U_W$, $U_A$, and $U_Y$ are the unmeasured exogenous background
characteristics that influence the value of each variable. Alternatively, the
same causal relations among variables can be represented with a series of equations:

\begin{eqnarray*}
W &=& f_W(U_W) \\
A &=& f_A(W,U_A) \\
Y&=&f_Y(W,A,U_Y).
\end{eqnarray*}

Here $f_W, f_A$ and $f_Y$ denote that each variable ($W, A$ and $Y$
respectively) is a function of its parents and unmeasured background
characteristics, but there is no imposition of any particular functional
constraints.  For this reason, these equations represent a *non-parametric
structural equation model (NPSEM)* @pearl2009causality. The DAG and this series
of non-parametric structural equations represent the same information.

Let's consider a hypothetical experiment in which we assign the
exposure to the whole population and observe the outcome, and then assign no
exposure to the whole population and observe the outcome. This hypothetical
experiment is "counterfactual" and thus can never be observed in practice, but
allows one to imagine an ideal experiment in which we observe everyone's
potential outcome. On the NPSEM, this corresponds to a comparison of the outcome
distribution in the population under two interventions: 1) $A$ is set to 1 for all individuals, and 2) $A$ is set to 0 for all individuals. These interventions imply two post-intervention NPSEMs with first being:
\begin{eqnarray*}
W &=& f_W(U_W) \\
A &=& 1 \\
Y(1)&=&f_Y(W,1,U_Y),
\end{eqnarray*}
and second just replacing the intervention of $A=1$ to $A=0$,
\begin{eqnarray*}
W &=& f_W(U_W) \\
A &=& 0 \\
Y(0)&=&f_Y(W,0,U_Y).
\end{eqnarray*}

In these equations, $A$ is no longer a function of $W$ because we have
intervened on the graph and set $A$ to the values 1 and 0. The new symbols
$Y(1)$ and $Y(0)$ indicate the outcome variable in our population if it were
generated by the respective NPSEMs above; often called counterfactuals. The
difference between the means of the outcome under these two interventions
defines a parameter that is often called the “Average Treatment Effect (ATE), or
\begin{equation}
\label{ate}
ATE = E_X(Y(1)-Y(0)),
\end{equation}
where $E_X$ is the mean under the theoretical full data: $X=(W,Y(1),Y(0))$.
Because we can never observe both $Y(0)$ (counterfactual when $A=0$) and $Y(1)$,
we can not estimate \ref{ate} directly.  

### Identifiability
We have to make assumptions to estimate this quantity from $O \sim P_0$, or the
data-generating distribution. Fortunately, given our causal model shown in the
graph above, we can, with a couple of more assumptions, estimate the ATE even
from observational data. First, the causal graph implies that $Y(a) \perp A$ for
all $a \in \mathcal{A}$, which is the randomization assumption. The
randomization assumption is also referred to as no unmeasured confounding or
*strong ignorability*. Outside of the graph, we also need to assume *no
interference*, the outcome for unit $i$ $Y_i$ is not affected by exposure for
unit $j$ $A_j$ unless $i=j$; *consistency*: the outcome for unit $i$ is $Y_i(a)$
whenever $A_i = a$, also known as "no other versions of treatment”, and these
two assumptions (consistency and no interference) are jointly referred to as
*stable unit value of treatment assignment (SUTVA)*. We also need to make the
positivity assumption ($0<P_0(A=a\mid W)< 1$ for all $a$ and $W$) for our target
parameter to be well defined. Given these assumptions, then we can re-write the target parameter as a function of the observed data distribution.

Continuing from our example above, we may write the ATE as a function of $P_0$.
Specifically,
\begin{equation}
\label{estimand}
ATE = E_0(Y(1)=Y(0)) = E_0\left( E_0[Y \mid A=1,W]-E_0[Y \mid A=0,W] \right),
\end{equation}
or the difference in predicted values for each subject in population and then
averaging over those subjects.

Thus, a parameter of a theoretical "full" data distribution can be represented
as an estimand of the observed data distribution. Moreover, there is nothing
about the representation in \ref{estimand} that requires parameteric
assumptions, so that the regressions on the right hand side of the equation
above can be estimated freely with machine learning. With
different parameters, there may be different/additional identifiability
assumptions and the resulting estimands can be functions of different components
of $P_0$. We discuss several more complex ones in this workshop later.
